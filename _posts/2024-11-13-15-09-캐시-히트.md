---
layout: post
title: "캐시 히트"
date: 2024-11-13
categories: [Computer_science]
tags: [computer_struct, hardware, cache, memory]
---
[캐시히트](https://blog.naver.com/techref/222290234374)
# 캐시 히트(Cache Hit)와 캐시 미스(Cache Miss)

캐시 메모리는 CPU와 주 메모리 사이의 속도 차이를 줄이기 위한 고속 메모리이다. 데이터 접근 패턴에 따라 성능이 크게 달라질 수 있다.
## 캐시 히트와 미스의 이해

### 캐시 히트 (Cache Hit)
- CPU가 요청한 데이터가 캐시 메모리에 있는 경우
- 매우 빠른 접근 시간 (L1의 경우 보통 1~5 클록 사이클)
- 메인 메모리 접근이 필요 없음
- 프로그램 실행 속도가 빠름

### 캐시 미스 (Cache Miss)
- CPU가 요청한 데이터가 캐시에 없는 경우
- 메인 메모리에서 데이터를 가져와야 함
- 상대적으로 긴 접근 시간 (메인 메모리의 경우 수백 클록 사이클)
- 성능 저하의 주요 원인

### 캐시 미스의 종류
1. **강제 미스 (Compulsory Miss)**
   - 데이터에 처음 접근할 때 발생
   - 캐시가 비어있는 상태에서 필연적으로 발생

2. **용량 미스 (Capacity Miss)**
   - 캐시 메모리 용량 부족으로 발생
   - 캐시 크기보다 더 많은 데이터를 사용할 때 발생

3. **충돌 미스 (Conflict Miss)**
   - 서로 다른 데이터가 같은 캐시 라인에 매핑될 때 발생
   - 캐시 구조(N-way set associative)에 따라 발생 빈도가 달라짐

## 메모리 접근 패턴

1. **순차적 접근 (Sequential Access)**
   - 메모리를 연속적으로 접근
   - 캐시 히트율이 높음
   - 하드웨어 프리페처(prefetcher)가 효과적으로 동작

2. **비순차적 접근 (Non-sequential Access)**
   - 메모리를 불연속적으로 접근
   - 캐시 미스율이 높음
   - 메모리 지연시간 증가

[하드웨어 프리페처](https://fiveable.me/key-terms/advanced-computer-architecture/hardware-prefetchers)
## 하드웨어 프리페처 
 CPU내에 구현된 메모리 최적화 메커니즘이다
 CPU가 실제 데이터를 요청하기 전에, 필요할것으로 예상되는 데이터를 미리 메모리에서 캐시로 가져온다
 공간적, 시간적 지연성 모두 고려한다
 틀릴 경우 캐시 오염으로 이어질 수 있다
1. **동작 방식**
   - 메모리 접근 패턴을 실시간으로 분석
   - 다음에 필요할 것 같은 데이터를 예측
   - 예측된 데이터를 미리 캐시로 가져옴

2. **장점**
   - 순차적 접근 시 매우 효과적
   - 캐시 히트율 향상
   - 메모리 지연 시간 감소

3. **예시**
   - 배열의 순차적 접근
   - 연속된 메모리 주소 읽기
   - 반복적인 메모리 접근 패턴

## 공간적 지역성
근처의 메모리에 액세스 하는 경향이 있는것
## 시간적 지역성
최근에 액세스한 메모리에 다시 엑세스 하는 경향이 있는것

## 실제 예시 코드

<div class="code-block-container">
    <button class="code-toggle">Expand</button>
    {% highlight csharp %}
using System.Diagnostics;

class Program
{
    static void Main(string[] args)
    {
        int[][] array1 = new int[1000][];

        for (int i = 0; i < array1.Length; i++) array1[i] = new int[1000];

        Stopwatch watch1 = new Stopwatch();
        Stopwatch watch2 = new Stopwatch();

        int[][]? array = array1;
        int temp = 0;

        watch1.Start();

        for (int i = 0; i < 1000; i++)
        {
            for (int j = 0; j < 1000; j++)
            {
                temp = array[i][j];
            }
        }

        watch1.Stop();

        // 밀리세컨드로 변환
        double elapsedMilliseconds1 = (double)watch1.ElapsedTicks / Stopwatch.Frequency * 1000;
        Console.WriteLine($"순차 접근 측정 시간 : {elapsedMilliseconds1} ms");

        int[][]? array2 = array1;
        int temp2 = 0;

        watch2.Start();

        for (int i = 0; i < 1000; i++)
        {
            for (int j = 0; j < 1000; j++)
            {
                temp2 = array2[j][i];
            }
        }

        watch2.Stop();

        // 밀리세컨드로 변환
        double elapsedMilliseconds2 = (double)watch2.ElapsedTicks / Stopwatch.Frequency * 1000;
        Console.WriteLine($"행우선 접근(띄엄띄엄) 측정 시간 : {elapsedMilliseconds2} ms");
    }
}
    {% endhighlight %}
</div>

### 결과 분석

1. **순차 접근**: 
   - 연속된 메모리 위치에 접근
   - 캐시 라인을 효율적으로 활용
   - 더 빠른 실행 시간

2. **행우선 접근**:
   - 메모리를 띄엄띄엄 접근
   - 잦은 캐시 미스 발생
   - 더 느린 실행 시간

이러한 성능 차이는 캐시의 지역성 원리(Locality of Reference)와 직접적인 관련이 있습니다.


## 메모리 계층별 접근 시간 (일반적인 현대 CPU 기준)

1. **L1 캐시**
   - 4-5 클록 사이클
   - 약 1-2 나노초

2. **L2 캐시**
   - 10-12 클록 사이클
   - 약 3-4 나노초

3. **L3 캐시**
   - 30-40 클록 사이클
   - 약 10-20 나노초

4. **메인 메모리 (RAM)**
   - 200-300 클록 사이클
   - 약 100 나노초